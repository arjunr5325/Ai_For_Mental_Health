{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opz_fK1WpnC_",
        "outputId": "f2fba3c8-6c96-489d-a423-37df443ccafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhufqqQAaz6e",
        "outputId": "be471745-8bea-4439-a567-1211cea9628c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!BUILD_CUDA_EXT=0 pip install -q auto-gptq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi_ynohXI847"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install accelerate peft transformers trl\n",
        "!pip install datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install tensorflow-model-optimization\n",
        "#!pip install trl\n",
        "#!pip install peft\n",
        "#!pip install -q -U transformers peft accelerate optimum\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/\n",
        "#!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg8NyBL0ZNyw"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import GPT2Tokenizer, TFGPT2Model, TFGPT2ForSequenceClassification\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9352jN0ZP6I",
        "outputId": "8179de6d-63a1-4d06-dd7b-7e55e483e3c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load quantize config, model and tokenizer\n",
        "quantize_config = BaseQuantizeConfig(\n",
        "    bits=4,\n",
        "    group_size=128,\n",
        "    damp_percent=0.01,\n",
        "    desc_act=False,\n",
        ")\n",
        "\n",
        "model_id = \"gpt2\"\n",
        "\n",
        "#model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "out_dir = model_id + \"-GPTQ\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, config=quantize_config, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmwCQtGmxubO",
        "outputId": "229c7bf9-f415-4d9b-eaa5-af7da78985d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/tokenizer_gpt2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/tokenizer_gpt2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/tokenizer_gpt2/vocab.json',\n",
              " '/content/drive/MyDrive/tokenizer_gpt2/merges.txt',\n",
              " '/content/drive/MyDrive/tokenizer_gpt2/added_tokens.json',\n",
              " '/content/drive/MyDrive/tokenizer_gpt2/tokenizer.json')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_path = '/content/drive/MyDrive/tokenizer_gpt2'\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(tokenizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r5CE1EV2JJf9",
        "outputId": "1854fedc-6096-4e12-be4c-8674daf2e1c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e49333e5-6d79-43e3-bf0f-46263fbca456\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comfortable_speaking_about_A_or_D</th>\n",
              "      <th>Friends_Family_A_or_D</th>\n",
              "      <th>Anxious_or_Depressed</th>\n",
              "      <th>A_or_D_more_than_once</th>\n",
              "      <th>MH9A</th>\n",
              "      <th>MH9B</th>\n",
              "      <th>MH9C</th>\n",
              "      <th>MH9D</th>\n",
              "      <th>MH9E</th>\n",
              "      <th>MH9F</th>\n",
              "      <th>MH9G</th>\n",
              "      <th>MH9H</th>\n",
              "      <th>Age</th>\n",
              "      <th>age_var2</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Household_Income</th>\n",
              "      <th>Subjective_Income</th>\n",
              "      <th>EMP_2010</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106142</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106143</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106144</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106145</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106146</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Comfortable speaking about Anxiety or Depressi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106147 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e49333e5-6d79-43e3-bf0f-46263fbca456')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e49333e5-6d79-43e3-bf0f-46263fbca456 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e49333e5-6d79-43e3-bf0f-46263fbca456');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-370fe102-bd33-4a97-bc26-ec664aa119f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-370fe102-bd33-4a97-bc26-ec664aa119f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-370fe102-bd33-4a97-bc26-ec664aa119f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7bffc381-61ef-4121-a319-b0cd31cfd84e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7bffc381-61ef-4121-a319-b0cd31cfd84e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Comfortable_speaking_about_A_or_D  Friends_Family_A_or_D  \\\n",
              "0                                       2                      1   \n",
              "1                                       2                      1   \n",
              "2                                       1                      1   \n",
              "3                                       3                      1   \n",
              "4                                       2                      1   \n",
              "...                                   ...                    ...   \n",
              "106142                                  2                      2   \n",
              "106143                                  3                      2   \n",
              "106144                                  3                      1   \n",
              "106145                                  3                      2   \n",
              "106146                                  1                      1   \n",
              "\n",
              "        Anxious_or_Depressed  A_or_D_more_than_once  MH9A  MH9B  MH9C  MH9D  \\\n",
              "0                          1                      1     3     2     1     2   \n",
              "1                          1                      1     2     2     2     4   \n",
              "2                          1                      1     1     1     1     1   \n",
              "3                          1                      1     1     4     2     1   \n",
              "4                          1                      1     1     4     1     2   \n",
              "...                      ...                    ...   ...   ...   ...   ...   \n",
              "106142                     0                      1     3     3     2     3   \n",
              "106143                     0                      2     4     4     2     2   \n",
              "106144                     0                      1     4     4     3     4   \n",
              "106145                     0                      1     4     3     2     2   \n",
              "106146                     0                      1     2     3     1     2   \n",
              "\n",
              "        MH9E  MH9F  MH9G  MH9H  Age  age_var2  Gender  Household_Income  \\\n",
              "0          2     2     3     3   78         4       1                 2   \n",
              "1          4     4     2     1   63         3       2                 2   \n",
              "2          4     1     1     1   72         4       2                 2   \n",
              "3          2     2     4     1   69         4       1                 5   \n",
              "4          2     4     1     1   34         2       2                 4   \n",
              "...      ...   ...   ...   ...  ...       ...     ...               ...   \n",
              "106142     3     2     3     3   40         2       1                 2   \n",
              "106143     2     2     3     2   30         2       1                 1   \n",
              "106144     2     4     3     1   19         1       2                 4   \n",
              "106145     3     4     2     2   48         2       2                 4   \n",
              "106146     2     3     2     2   32         2       1                 1   \n",
              "\n",
              "        Subjective_Income  EMP_2010  \\\n",
              "0                       4         6   \n",
              "1                       4         6   \n",
              "2                       2         6   \n",
              "3                       1         6   \n",
              "4                       1         1   \n",
              "...                   ...       ...   \n",
              "106142                  1         4   \n",
              "106143                  4         4   \n",
              "106144                  1         1   \n",
              "106145                  3         6   \n",
              "106146                  2         3   \n",
              "\n",
              "                                                     text  \n",
              "0       Comfortable speaking about Anxiety or Depressi...  \n",
              "1       Comfortable speaking about Anxiety or Depressi...  \n",
              "2       Comfortable speaking about Anxiety or Depressi...  \n",
              "3       Comfortable speaking about Anxiety or Depressi...  \n",
              "4       Comfortable speaking about Anxiety or Depressi...  \n",
              "...                                                   ...  \n",
              "106142  Comfortable speaking about Anxiety or Depressi...  \n",
              "106143  Comfortable speaking about Anxiety or Depressi...  \n",
              "106144  Comfortable speaking about Anxiety or Depressi...  \n",
              "106145  Comfortable speaking about Anxiety or Depressi...  \n",
              "106146  Comfortable speaking about Anxiety or Depressi...  \n",
              "\n",
              "[106147 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"class_0 = df[df['Anxious_or_Depressed'] == 0]\\nclass_1 = df[df['Anxious_or_Depressed'] == 1]\\n\\n# Sample an equal number of rows from each class\\nsample_size_per_class = 15000\\nsample_class_0 = class_0.sample(n=sample_size_per_class, random_state=42)\\nsample_class_1 = class_1.sample(n=sample_size_per_class, random_state=42)\\n\\n# Concatenate the sampled DataFrames\\nfirst_part = pd.concat([sample_class_0, sample_class_1])\\n\\n# Store the remaining samples in another DataFrame\\nsecond_part = df.drop(first_part.index)\\n\\ndf_dataset = Dataset.from_pandas(first_part[['text', 'Anxious_or_Depressed']])\\nnew_df = df_dataset.to_pandas()\\n\\ndisplay(new_df)\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"Random_Forest_Dataset.csv\")\n",
        "\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['Anxious_or_Depressed'] = df['Anxious_or_Depressed'].map({1: 1, 2: 0})\n",
        "\n",
        "#display(df)\n",
        "\n",
        "\n",
        "# Convert the binary features and labels into a text format\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "\n",
        "df['text'] = df.apply(row_to_text, axis=1)\n",
        "\n",
        "display(df)\n",
        "\n",
        "df_random_10k = df.sample(n=10000, random_state=42)\n",
        "remaining_df = df.drop(df_random_10k.index)\n",
        "\n",
        "\n",
        "'''class_0 = df[df['Anxious_or_Depressed'] == 0]\n",
        "class_1 = df[df['Anxious_or_Depressed'] == 1]\n",
        "\n",
        "# Sample an equal number of rows from each class\n",
        "sample_size_per_class = 15000\n",
        "sample_class_0 = class_0.sample(n=sample_size_per_class, random_state=42)\n",
        "sample_class_1 = class_1.sample(n=sample_size_per_class, random_state=42)\n",
        "\n",
        "# Concatenate the sampled DataFrames\n",
        "first_part = pd.concat([sample_class_0, sample_class_1])\n",
        "\n",
        "# Store the remaining samples in another DataFrame\n",
        "second_part = df.drop(first_part.index)\n",
        "\n",
        "df_dataset = Dataset.from_pandas(first_part[['text', 'Anxious_or_Depressed']])\n",
        "new_df = df_dataset.to_pandas()\n",
        "\n",
        "display(new_df)'''\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLfwjmg0JYNV"
      },
      "outputs": [],
      "source": [
        "# # Tokenize the dataset\n",
        "# tokenized_dataset = tokenizer(df, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "wx4m6NbgXFHu",
        "outputId": "94f7714e-23f3-4145-dc26-7c796568473b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 31:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.734400</td>\n",
              "      <td>0.663758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.669526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.605626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 01:52]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"first-10k-gpt2\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/first-10k-gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETsG2iYrXaUg"
      },
      "outputs": [],
      "source": [
        "'''%%time\n",
        "\n",
        "# Quantize with GPTQ\n",
        "model.quantize(\n",
        "    df_dataset,\n",
        "    batch_size=1,\n",
        "    use_triton=True,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_quantized(out_dir, use_safetensors=True)\n",
        "tokenizer.save_pretrained(out_dir)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Loa6-95EIEA",
        "outputId": "a8c6f8fb-9dd4-477f-cd2d-999108c6af66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['LABEL_0']\n",
            "The patient is not likely to be anxious or depressed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/gpt2-first-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "new_text = ['Comfortable speaking about Anxiety or Depression: very comfortable, Friends or Family Have Been Anxious or Depressed: yes, Have Felt Anxious or Depressed More Than Once: yes, How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: did not do, How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: did not do, How Helpful Was Talking to Friends or Family When Anxious or Depressed: very helpful, How Helpful Was Taking Prescribed Medication When Anxious or Depressed: did not do, How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: somewhat, How Helpful Was Making a Change to Work Situation When Anxious or Depressed: did not do, How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: very helpful, How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: somewhat, Gender: Female, Household_Income: Middle, Feelings About Household Income: Living comfortably, Employment Status: unknown']\n",
        "\n",
        "encoded_inputs = tokenizer(new_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encoded_inputs)\n",
        "\n",
        "# Getting predictions\n",
        "predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "# Convert predictions to labels\n",
        "predicted_labels = [model.config.id2label[p.item()] for p in predictions]\n",
        "\n",
        "print(predicted_labels)\n",
        "if predicted_labels == 'LABEL_1':\n",
        "  print('The patient is likely to be anxious or depressed')\n",
        "else:\n",
        "  print('The patient is not likely to be anxious or depressed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yxk2odpD25D",
        "outputId": "844ef503-d741-4f63-93c5-10d069d88e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 100: 0.88\n"
          ]
        }
      ],
      "source": [
        "df_100 = remaining_df.sample(n=100, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_100 = Dataset.from_pandas(df_100[['text', 'Anxious_or_Depressed']])\n",
        "new_df_100 = df_dataset_100.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-first-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_100['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_100['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 100:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdquLXMUPA5i",
        "outputId": "cdd914a7-25fb-4fd4-8e66-7b4165744ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.886\n"
          ]
        }
      ],
      "source": [
        "df_1000 = remaining_df.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-first-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFzv86efU39A",
        "outputId": "21841316-12e1-4a85-e9d3-b13cf684b6be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 5000: 0.8848\n"
          ]
        }
      ],
      "source": [
        "df_5000 = remaining_df.sample(n=5000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_5000 = Dataset.from_pandas(df_5000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_5000 = df_dataset_5000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-first-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_5000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_5000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 5000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrtihB6Jo5u4"
      },
      "outputs": [],
      "source": [
        "remaining_df.to_csv('remaining_df.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF6VhiXMqEwL"
      },
      "outputs": [],
      "source": [
        "#next 10k - 2nd iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "Zv4T8bjGqEoX",
        "outputId": "bb6d3950-6fbf-4bd3-f4ea-3d883c5012f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 35:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.737200</td>\n",
              "      <td>0.666491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.762300</td>\n",
              "      <td>0.718223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.689800</td>\n",
              "      <td>0.664495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 02:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "# Load the tokenizer using the model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "remaining_df_90k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_90k.csv\")\n",
        "remaining_df_90k['text'] = remaining_df_90k.apply(row_to_text, axis=1)\n",
        "\n",
        "df_random_10k = remaining_df_90k.sample(n=10000, random_state=42)\n",
        "\n",
        "remaining_df_80k = remaining_df_90k.drop(df_random_10k.index)\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"gpt2-second-10k-for-disease-prediction-4bit\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/gpt2-second-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "remaining_df_80k.to_csv('/content/drive/MyDrive/remaining_df_80k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkSCmcLt_gyi",
        "outputId": "eb5ec264-e47a-4289-a0a5-c5c66ba97346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.904\n"
          ]
        }
      ],
      "source": [
        "df_1000 = remaining_df_80k.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-second-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9cJPDJmAdNT"
      },
      "outputs": [],
      "source": [
        "#iteration 3 -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "-r8Z6VChAfv8",
        "outputId": "8e2fa507-aa3b-4f0a-dcab-cc94610685a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 33:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.764000</td>\n",
              "      <td>0.733437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.681600</td>\n",
              "      <td>0.684694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.652698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 01:55]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/gpt2-second-10k-for-disease-prediction-4bit\")\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "# Load the tokenizer using the model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "remaining_df_80k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_80k.csv\")\n",
        "remaining_df_80k['text'] = remaining_df_80k.apply(row_to_text, axis=1)\n",
        "\n",
        "df_random_10k = remaining_df_80k.sample(n=10000, random_state=42)\n",
        "\n",
        "remaining_df_70k = remaining_df_80k.drop(df_random_10k.index)\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"gpt2-third-10k-for-disease-prediction-4bit\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/gpt2-third-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "remaining_df_70k.to_csv('/content/drive/MyDrive/remaining_df_70k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ay-yCeLAflv",
        "outputId": "7d4a7137-343c-4817-f50f-4672a1285bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.895\n"
          ]
        }
      ],
      "source": [
        "df_1000 = remaining_df_70k.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-third-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5EOhPTyL72C"
      },
      "outputs": [],
      "source": [
        "#iteration 4 -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "-cGNODRCL9f8",
        "outputId": "4011ae26-9bf6-4b0c-809b-a56d6f656ea0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 31:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.564100</td>\n",
              "      <td>0.696696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.666167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.557200</td>\n",
              "      <td>0.639092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 01:52]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/gpt2-third-10k-for-disease-prediction-4bit\")\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "# Load the tokenizer using the model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "remaining_df_70k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_70k.csv\")\n",
        "remaining_df_70k['text'] = remaining_df_70k.apply(row_to_text, axis=1)\n",
        "\n",
        "df_random_10k = remaining_df_70k.sample(n=10000, random_state=42)\n",
        "\n",
        "remaining_df_60k = remaining_df_70k.drop(df_random_10k.index)\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"gpt2-fourth-10k-for-disease-prediction-4bit\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/gpt2-fourth-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "remaining_df_60k.to_csv('/content/drive/MyDrive/remaining_df_60k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8As-tXzzVAEp"
      },
      "outputs": [],
      "source": [
        "remaining_df_60k.to_csv('/content/drive/MyDrive/remaining_df_60k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsEdiTfmL9RU",
        "outputId": "ffcaed1c-711a-4da6-fae8-5cc5261c4cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.9\n"
          ]
        }
      ],
      "source": [
        "df_1000 = remaining_df_60k.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-fourth-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnALegqjQojw"
      },
      "outputs": [],
      "source": [
        "#iteration 5 -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "WaTyh6ufHZRM",
        "outputId": "0533df30-6343-4173-ad85-fd45cd0229fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 34:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.726300</td>\n",
              "      <td>0.707067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.774600</td>\n",
              "      <td>0.641641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.535300</td>\n",
              "      <td>0.637129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 01:55]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/gpt2-fourth-10k-for-disease-prediction-4bit\")\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "# Load the tokenizer using the model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "remaining_df_60k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_60k.csv\")\n",
        "remaining_df_60k['text'] = remaining_df_60k.apply(row_to_text, axis=1)\n",
        "\n",
        "df_random_10k = remaining_df_60k.sample(n=10000, random_state=42)\n",
        "\n",
        "remaining_df_50k = remaining_df_60k.drop(df_random_10k.index)\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"gpt2-fifth-10k-for-disease-prediction-4bit\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/gpt2-fifth-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "remaining_df_50k.to_csv('/content/drive/MyDrive/remaining_df_50k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvGZciwiHZKV",
        "outputId": "4485c5ab-9be9-4d4c-ed7d-6da7f4d36778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.899\n"
          ]
        }
      ],
      "source": [
        "df_1000 = remaining_df_50k.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-fifth-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3C3AE3HRsMP"
      },
      "outputs": [],
      "source": [
        "#iteration 6 -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "gYnJH5kHRtmG",
        "outputId": "d9f0bcbc-11de-48a1-d017-1bbd5b2afb41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30000/30000 33:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.695003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.534500</td>\n",
              "      <td>0.682979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.622800</td>\n",
              "      <td>0.684122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 01:52]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/gpt2-fifth-10k-for-disease-prediction-4bit\")\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "# Load the tokenizer using the model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "def tokenize_batch(batch_text):\n",
        "    # Tokenize each text in the batch\n",
        "    return tokenizer(batch_text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def row_to_text(row):\n",
        "    text = (f\"Comfortable speaking about Anxiety or Depression: {'very comfortable' if row['Comfortable_speaking_about_A_or_D'] == 1 else 'somewhat' if row['Comfortable_speaking_about_A_or_D'] == 2 else 'no' if row['Comfortable_speaking_about_A_or_D'] == 3 else 'unknown'}, \"\n",
        "           f\"Friends or Family Have Been Anxious or Depressed: {'yes' if row['Friends_Family_A_or_D'] else 'no'}, \"\n",
        "           f\"Have Felt Anxious or Depressed More Than Once: {'yes' if row['A_or_D_more_than_once'] == 1 else 'no'}, \"\n",
        "           f\"How Helpful Was Talking to Mental Health Professional When Anxious or Depressed: {'very helpful' if row['MH9A'] == 1 else 'somewhat' if row['MH9A'] == 2 else 'no' if row['MH9A'] == 3 else 'did not do' if row['MH9A'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Engaging in Religious or Spiritual Activities When Anxious or Depressed: {'very helpful' if row['MH9B'] == 1 else 'somewhat' if row['MH9B'] == 2 else 'no' if row['MH9B'] == 3 else 'did not do' if row['MH9B'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Talking to Friends or Family When Anxious or Depressed: {'very helpful' if row['MH9C'] == 1 else 'somewhat' if row['MH9C'] == 2 else 'no' if row['MH9C'] == 3 else 'did not do' if row['MH9C'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Taking Prescribed Medication When Anxious or Depressed: {'very helpful' if row['MH9D'] == 1 else 'somewhat' if row['MH9D'] == 2 else 'no' if row['MH9D'] == 3 else 'did not do' if row['MH9D'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Improving Healthy Lifestyle Behaviours When Anxious or Depressed: {'very helpful' if row['MH9E'] == 1 else 'somewhat' if row['MH9E'] == 2 else 'no' if row['MH9E'] == 3 else 'did not do' if row['MH9E'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Work Situation When Anxious or Depressed: {'very helpful' if row['MH9F'] == 1 else 'somewhat' if row['MH9F'] == 2 else 'no' if row['MH9F'] == 3 else 'did not do' if row['MH9F'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Making a Change to Personal Relationships When Anxious or Depressed: {'very helpful' if row['MH9G'] == 1 else 'somewhat' if row['MH9G'] == 2 else 'no' if row['MH9G'] == 3 else 'did not do' if row['MH9G'] == 4 else 'unknown'}, \"\n",
        "           f\"How Helpful Was Spending Time in Nature or The Outdoors When Anxious or Depressed: {'very helpful' if row['MH9H'] == 1 else 'somewhat' if row['MH9H'] == 2 else 'no' if row['MH9H'] == 3 else 'did not do' if row['MH9H'] == 4 else 'unknown'}, \"\n",
        "           f\"Gender: {'Male' if row['Gender'] == 1 else 'Female'}, \"\n",
        "           f\"Household_Income: {'Poorest' if row['Household_Income'] == 1 else 'Second poorest' if row['Household_Income'] == 2 else 'Middle' if row['Household_Income'] == 3 else 'Rich' if row['Household_Income'] == 4 else 'Richest' if row['Household_Income'] == 5 else 'unknown'}, \"\n",
        "           f\"Feelings About Household Income: {'Living comfortably' if row['Subjective_Income'] == 1 else 'Getting by' if row['Subjective_Income'] == 2 else 'Finding it difficult' if row['Subjective_Income'] == 3 else 'Finding it very difficult' if row['Subjective_Income'] == 4 else 'dont know' if row['Subjective_Income'] == 5 else 'refused' if row['Subjective_Income'] == 6 else 'unknown'}, \"\n",
        "           f\"Employment Status: {'Full time for an employer' if row['EMP_2010'] == 1 else 'Full time for self' if row['EMP_2010'] == 2 else 'Part time' if row['EMP_2010'] == 3 else 'Unemployed' if row['EMP_2010'] == 4 else 'Part time, want full time' if row['EMP_2010'] == 5 else 'Out of workforce' if row['EMP_2010'] == 6 else 'unknown'}\")\n",
        "    return text\n",
        "\n",
        "remaining_df_50k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_50k.csv\")\n",
        "remaining_df_50k['text'] = remaining_df_50k.apply(row_to_text, axis=1)\n",
        "\n",
        "df_random_10k = remaining_df_50k.sample(n=10000, random_state=42)\n",
        "\n",
        "remaining_df_40k = remaining_df_50k.drop(df_random_10k.index)\n",
        "tokenized_datasets = tokenize_batch(df_random_10k['text'].tolist())\n",
        "\n",
        "tokenized_datasets['labels'] = torch.tensor(df_random_10k['Anxious_or_Depressed'].tolist())\n",
        "\n",
        "# Convert tokenized datasets to PyTorch Dataset object\n",
        "tokenized_datasets = Dataset.from_dict(tokenized_datasets)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"gpt2-sixth-10k-for-disease-prediction-4bit\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/gpt2-sixth-10k-for-disease-prediction-4bit\")\n",
        "\n",
        "remaining_df_40k.to_csv('/content/drive/MyDrive/remaining_df_40k.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQIIITaW_Kgp",
        "outputId": "c4c93765-a6a2-41d0-f165-e5258a94f1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 4 bit quantised gpt2 model on test size 1000: 0.898\n"
          ]
        }
      ],
      "source": [
        "remaining_df_40k = pd.read_csv(\"/content/drive/MyDrive/remaining_df_40k.csv\")\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer_gpt2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "df_1000 = remaining_df_40k.sample(n=1000, random_state=42)\n",
        "\n",
        "#df_100.head(5)\n",
        "\n",
        "df_dataset_1000 = Dataset.from_pandas(df_1000[['text', 'Anxious_or_Depressed']])\n",
        "new_df_1000 = df_dataset_1000.to_pandas()\n",
        "\n",
        "#display(new_df_100)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/gpt2-sixth-10k-for-disease-prediction-4bit')\n",
        "\n",
        "\n",
        "# Tokenize the new data\n",
        "new_texts = df_1000['text'].tolist()\n",
        "\n",
        "\n",
        "# Initialize an empty list to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Perform inference for each input and store predictions\n",
        "for text in new_texts:\n",
        "    # Tokenize the input\n",
        "    encoded_inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "\n",
        "    # Getting predictions\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions to labels and append to list\n",
        "    predicted_label = model.config.id2label[predictions[0].item()]\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predicted labels to integers\n",
        "predicted_labels_int = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Ground truth labels\n",
        "ground_truth_labels = df_1000['Anxious_or_Depressed'].tolist()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(ground_truth_labels, predicted_labels_int)\n",
        "\n",
        "print(\"Accuracy of 4 bit quantised gpt2 model on test size 1000:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fosvd0WRtdU",
        "outputId": "30a4ad6b-f391-484c-c2c0-4f364423a132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "# Load the test dataset from a CSV file\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/remaining_df_40k.csv')\n",
        "\n",
        "# Remove the 'text' feature\n",
        "test_df.drop('text', axis=1, inplace=True)\n",
        "\n",
        "# Load the trained model from your Google Drive\n",
        "model_path = '/content/drive/MyDrive/gpt2-sixth-10k-for-disease-prediction-4bit'\n",
        "config = AutoConfig.from_pretrained(model_path + '/config.json')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Convert features to tensor\n",
        "features_tensor = torch.tensor(test_df.values, dtype=torch.long)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=features_tensor)\n",
        "\n",
        "# Convert outputs to probabilities\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "\n",
        "# Assuming the first class is 'no mental illness' and the second class is 'mental illness'\n",
        "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
        "\n",
        "# Add predictions to the test dataset\n",
        "test_df['predictions'] = predictions\n",
        "\n",
        "# Save the updated test dataset with predictions\n",
        "test_df.to_csv('/content/lol', index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc0NguRyJhS9",
        "outputId": "9be2cd09-c22c-4380-8b5b-1eb5b607938c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
